{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d5b371-3401-4be9-8558-bdb3e4693775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d236b-e10c-4379-b6d8-d1d40d79536f",
   "metadata": {},
   "source": [
    "## System Components and Workflow\n",
    "The system consists of four main AI agents, each responsible for a specific step in the API integration process.\n",
    "\n",
    "- **Search Agent (Finding Relevant APIs)**\n",
    "Uses FAISS to store and retrieve API documentation efficiently.\n",
    "Extracts keywords from user queries using SpaCy.\n",
    "Encodes text using SentenceTransformers for similarity search.\n",
    "- **Code Agent (Generating API Integration Code)**\n",
    "Uses Ollama (Llama3) to generate backend (FastAPI) and frontend (JavaScript) code.\n",
    "Ensures the generated API calls follow Sikka's specifications.\n",
    "- **Review Agent (Evaluating and Scoring Code Quality)**\n",
    "Reviews generated code for errors, inefficiencies, and best practices.\n",
    "Provides a quality score (1-10) to determine if modifications are needed.\n",
    "- **Manager Agent (Orchestrating Workflow and Decision-Making)**\n",
    "Decides whether the code should be fixed, retried, or finalized.\n",
    "Requests further API searches if needed.\n",
    "Formats the final submission output.\n",
    "- **Submit Agent (Final Code Formatting)**\n",
    "Summarizes and structures the final output.\n",
    "Incorporates feedback from the review process.\n",
    "Ensures the submission is well-documented and formatted for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f18e3cf-ca69-4601-a107-2d1e4d7724e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a6bdd3-76f5-42ce-be0c-c97bb621ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SearchAgent:\n",
    "#     \"\"\"Search API documentation using FAISS and refine results using LLM\"\"\"\n",
    "#     def __init__(self, docs, embedder, index, doc_map, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "#         self.docs = docs\n",
    "#         self.embedder = embedder\n",
    "#         self.index = index\n",
    "#         self.doc_map = doc_map\n",
    "#         self.llm = OpenAIChatCompletionClient(\n",
    "#             model=model, base_url=model_url, api_key=key,\n",
    "#             model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "#         )\n",
    "\n",
    "#     def search(self, query: str, top_k=3):\n",
    "#         \"\"\"Retrieve the most relevant API documentation based on user request using FAISS search\"\"\"\n",
    "#         query_vec = self.embedder.encode([query])\n",
    "#         _, indices = self.index.search(query_vec, top_k)\n",
    "#         return [self.doc_map[i] for i in indices[0] if i in self.doc_map]\n",
    "\n",
    "#     async def query_api(self, question, retrieved_docs):\n",
    "#         \"\"\"Use LLM to analyze API details and return structured answers\"\"\"\n",
    "#         combined_docs = \"\\n\\n\".join(retrieved_docs)\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": f\"You are an AI assistant helping developers integrate Sikka APIs.\\nRelevant API documentation:\\n{combined_docs}\"},\n",
    "#             {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnalyze the above API documentation and provide a structured answer.\"}\n",
    "#         ]\n",
    "#         response = await self.llm.create([UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages])\n",
    "#         return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3fb7a66-f9f8-4ed6-88cf-9862d51a12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "\n",
    "class SearchAgent:\n",
    "    \"\"\"Search API documentation using FAISS and refine results using LLM\"\"\"\n",
    "\n",
    "    def __init__(self, docs, embedder, index, doc_map, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "        self.docs = docs\n",
    "        self.embedder = embedder\n",
    "        self.index = index\n",
    "        self.doc_map = doc_map\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")  # Load SpaCy for keyword extraction\n",
    "\n",
    "        self.llm = OpenAIChatCompletionClient(\n",
    "            model=model, base_url=model_url, api_key=key,\n",
    "            model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "    def extract_keywords(self, query):\n",
    "        \"\"\"Extracts important keywords from the user query to improve search accuracy\"\"\"\n",
    "        doc = self.nlp(query)\n",
    "        keywords = [token.lemma_ for token in doc if token.pos_ in [\"NOUN\", \"VERB\", \"PROPN\"]]  \n",
    "        return \" \".join(keywords)  \n",
    "\n",
    "    def search(self, query: str, top_k=3):\n",
    "        \"\"\"Retrieves the most relevant API documents using FAISS\"\"\"\n",
    "        refined_query = self.extract_keywords(query)\n",
    "        print(f\"Extracted query keywords: {refined_query}\")\n",
    "\n",
    "        query_vec = self.embedder.encode([refined_query])\n",
    "        _, indices = self.index.search(query_vec, top_k)\n",
    "\n",
    "        return [self.doc_map[i] for i in indices[0] if i in self.doc_map]\n",
    "\n",
    "    async def query_api(self, question, retrieved_docs):\n",
    "        \"\"\"Uses LLM to analyze API details and return structured answers\"\"\"\n",
    "        combined_docs = \"\\n\\n\".join(retrieved_docs)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"You are an AI assistant helping developers integrate Sikka APIs.\\nRelevant API documentation:\\n{combined_docs}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nAnalyze the above API documentation and provide a structured answer.\"}\n",
    "        ]\n",
    "        response = await self.llm.create([UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages])\n",
    "        return response.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5907ad8-dbd0-46a1-bfc8-6ed0c3a0b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeAgent:\n",
    "    \"\"\"Generate API integration code using relevant API documentation\"\"\"\n",
    "    def __init__(self, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "        self.client = OpenAIChatCompletionClient(\n",
    "            model=model, base_url=model_url, api_key=key,\n",
    "            model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "    async def chat(self, messages):\n",
    "        \"\"\"Send input to the language model and retrieve a response\"\"\"\n",
    "        msg_list = [UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages]\n",
    "        response = await self.client.create(msg_list)\n",
    "        return response.content.strip()\n",
    "\n",
    "    async def generate_code(self, request: str, docs):\n",
    "        \"\"\"Generate backend and frontend integration code using relevant API documentation\"\"\"\n",
    "        docs_text = \"\\n\\n\".join(docs)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"Generate code using Sikka APIs. Relevant documentation:\\n{docs_text}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Requirement: {request}\\nGenerate backend (FastAPI/Flask) and frontend (JavaScript) code.\"}\n",
    "        ]\n",
    "        return await self.chat(messages)\n",
    "\n",
    "    async def fix_code(self, request: str, feedback: str, original_code: str):\n",
    "        \"\"\"Modify generated code based on ReviewAgent's feedback\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"Fix the following code based on review feedback:\\n{original_code}\\n\\nFeedback:\\n{feedback}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Requirement: {request}\\nPlease improve the code while keeping it simple and correct.\"}\n",
    "        ]\n",
    "        return await self.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da2cacc-62ac-42af-bf6c-2e4443a823e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewAgent:\n",
    "    \"\"\"Review the generated code and provide feedback\"\"\"\n",
    "    def __init__(self, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "        self.llm = OpenAIChatCompletionClient(\n",
    "            model=model, base_url=model_url, api_key=key,\n",
    "            model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "    async def review(self, code: str):\n",
    "        \"\"\"Evaluate whether the generated code follows best practices\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI code reviewer. Review the given API integration code and identify issues.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Code to review:\\n{code}\\n\\nList any potential issues and improvements.\"}\n",
    "        ]\n",
    "        response = await self.llm.create([UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages])\n",
    "        return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845576b0-f018-40ac-a529-30a5930e679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmitAgent:\n",
    "    \"\"\"Summarize and format the final output for submission to the client\"\"\"\n",
    "    def __init__(self, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "        self.llm = OpenAIChatCompletionClient(\n",
    "            model=model, base_url=model_url, api_key=key,\n",
    "            model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "    async def format_submission(self, code: str, review: str, decision: str):\n",
    "        \"\"\"Summarize and refine the final code with structured comments.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that formats code for submission. Improve readability, add necessary comments, and structure the response in a professional format.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the final code:\\n{code}\\n\\nReview feedback:\\n{review}\\n\\nManager decision:\\n{decision}\\n\\nFormat this into a clean, well-documented output for submission.\"}\n",
    "        ]\n",
    "        response = await self.llm.create([UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages])\n",
    "        return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02394a9d-9473-4fcd-b061-60621ff4f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager:\n",
    "    \"\"\"Handle API search, code generation, and review process using LLM\"\"\"\n",
    "    def __init__(self, search_agent, code_agent, review_agent, submit_agent, model_url=\"http://localhost:11434/v1\", key=\"ollama\", model=\"llama3.2:latest\"):\n",
    "        self.search_agent = search_agent\n",
    "        self.code_agent = code_agent\n",
    "        self.review_agent = review_agent\n",
    "        self.submit_agent = submit_agent\n",
    "        self.llm = OpenAIChatCompletionClient(\n",
    "            model=model, base_url=model_url, api_key=key,\n",
    "            model_info={\"vision\": False, \"function_calling\": True, \"json_output\": False, \"family\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "    async def decide_action(self, user_request, code, feedback):\n",
    "        \"\"\"Use LLM to decide whether to fix code, retry search, or return result\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent AI that manages API integration workflows. Your job is to decide whether the code needs to be fixed or if API search should be refined.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"User request: {user_request}\\n\\nGenerated code:\\n{code}\\n\\nReview feedback:\\n{feedback}\\n\\nShould the code be fixed, or should API selection be improved? Provide a clear action plan.\"}\n",
    "        ]\n",
    "        response = await self.llm.create([UserMessage(content=m[\"content\"], source=m[\"role\"]) for m in messages])\n",
    "        return response.content.strip()\n",
    "\n",
    "    async def process_request(self, user_request):\n",
    "        \"\"\"Find relevant API documentation, generate code, review it, and decide next steps\"\"\"\n",
    "        docs = self.search_agent.search(user_request)\n",
    "        code = await self.code_agent.generate_code(user_request, docs)\n",
    "        feedback = await self.review_agent.review(code)\n",
    "\n",
    "        decision = await self.decide_action(user_request, code, feedback)\n",
    "\n",
    "        if \"fix the code\" in decision.lower():\n",
    "            print(\"Manager decided to request CodeAgent to modify the code...\")\n",
    "            fixed_code = await self.code_agent.fix_code(user_request, feedback, code)\n",
    "            final_code = fixed_code\n",
    "        elif \"search again\" in decision.lower():\n",
    "            print(\"Manager decided to refine API search...\")\n",
    "            refined_docs = self.search_agent.search(user_request + \" API integration\")\n",
    "            refined_code = await self.code_agent.generate_code(user_request, refined_docs)\n",
    "            final_code = refined_code\n",
    "        else:\n",
    "            final_code = code\n",
    "\n",
    "        submission = await self.submit_agent.format_submission(final_code, feedback, decision)\n",
    "        return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7dd655-4638-438f-985b-5fd852640d34",
   "metadata": {},
   "source": [
    "### Method1: Suitable for one-time execution or when the API changes frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b475531-eb31-4a5b-ae02-eab5efe539a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def run_system(user_request):\n",
    "#     \"\"\"Initialize agents and process a user request for API integration\"\"\"\n",
    "#     try:\n",
    "#         api_df = pd.read_csv(\"Sikka_APIs - Sikka_APIs.csv\")\n",
    "#         docs = [\n",
    "#             f\"API: {row.get('API Name', '')}\\nDescription: {row.get('Description', '')}\\n\"\n",
    "#             f\"Endpoints: {row.get('API Endpoints', '')}\\nDoc: {row.get('Document Link', '')}\"\n",
    "#             for _, row in api_df.iterrows()\n",
    "#         ]\n",
    "#     except:\n",
    "#         docs = [\"Sikka APIs include payments, patient data, scheduling, billing, and financial services.\"]\n",
    "\n",
    "#     embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "#     doc_vectors = embedder.encode(docs)\n",
    "#     index = faiss.IndexFlatL2(doc_vectors.shape[1])\n",
    "#     index.add(doc_vectors)\n",
    "#     doc_map = {i: docs[i] for i in range(len(docs))}\n",
    "    \n",
    "#     search_agent = SearchAgent(docs, embedder, index, doc_map)\n",
    "#     code_agent = CodeAgent()\n",
    "#     review_agent = ReviewAgent()\n",
    "#     submit_agent = SubmitAgent()\n",
    "#     manager = Manager(search_agent, code_agent, review_agent, submit_agent)\n",
    "    \n",
    "#     return await manager.process_request(user_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d180e-9d76-472d-9cda-a377202bd508",
   "metadata": {},
   "source": [
    "### Method2: Suitable for production environments, with reusable indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9caaaad9-4d05-499a-9dd8-62f7f83f6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_or_build_faiss_index(docs, embedder, index_path=\"sikka_api.index\"):\n",
    "    \"\"\"Load an existing FAISS index, or create and save a new one if not found\"\"\"\n",
    "    if os.path.exists(index_path):\n",
    "        print(\"Loading existing FAISS index...\")\n",
    "        index = faiss.read_index(index_path)\n",
    "    else:\n",
    "        print(\"Computing embeddings and creating a new index...\")\n",
    "        doc_vectors = embedder.encode(docs)\n",
    "        index = faiss.IndexFlatL2(doc_vectors.shape[1])  # Create an L2 distance index\n",
    "        index.add(np.array(doc_vectors).astype(\"float32\"))\n",
    "        faiss.write_index(index, index_path)  # Save the index\n",
    "\n",
    "    return index\n",
    "\n",
    "async def run_system(user_request):\n",
    "    \"\"\"Initialize the agents and process the user request\"\"\"\n",
    "    try:\n",
    "        api_df = pd.read_csv(\"Sikka_APIs - Sikka_APIs.csv\")\n",
    "        docs = [\n",
    "            f\"API: {row.get('API Name', '')}\\nDescription: {row.get('Description', '')}\\n\"\n",
    "            f\"Endpoints: {row.get('API Endpoints', '')}\\nDoc: {row.get('Document Link', '')}\"\n",
    "            for _, row in api_df.iterrows()\n",
    "        ]\n",
    "    except:\n",
    "        docs = [\"Sikka APIs include payments, patient data, scheduling, billing, and financial services.\"]\n",
    "\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Use a persistent FAISS index\n",
    "    index = load_or_build_faiss_index(docs, embedder)\n",
    "\n",
    "    # Create an API document index mapping\n",
    "    doc_map = {i: docs[i] for i in range(len(docs))}\n",
    "    \n",
    "    # Initialize agents\n",
    "    search_agent = SearchAgent(docs, embedder, index, doc_map)\n",
    "    code_agent = CodeAgent()\n",
    "    review_agent = ReviewAgent()\n",
    "    submit_agent = SubmitAgent()\n",
    "    manager = Manager(search_agent, code_agent, review_agent, submit_agent)\n",
    "    \n",
    "    return await manager.process_request(user_request)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5539c5d2-4e1a-4d7c-9a03-85f581b4e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Execute the full system with a sample request.\"\"\"\n",
    "    request = \"I want to build a doctor payment system with FastAPI and a JavaScript frontend.\"\n",
    "    result = await run_system(request)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6630f1be-48a8-4e32-b04f-aad858a522fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS index...\n",
      "Extracted query keywords: want build doctor payment system fastapi JavaScript frontend\n",
      "Based on the review feedback and existing code, I will provide an updated version of the `main.py` file that includes improvements in error handling and API key management:\n",
      "\n",
      "```python\n",
      "from fastapi import FastAPI, Depends\n",
      "import requests\n",
      "\n",
      "class APIKeySecret:\n",
      "    def __init__(self, api_key, balance_id, payment_plans_api_key):\n",
      "        self.api_key = api_key\n",
      "        self.balance_id = balance_id\n",
      "        self.payment_plans_api_key = payment_plans_api_key\n",
      "\n",
      "@app.get(\"/balance\")\n",
      "def get_patient_balance(patient_id: str, apikey_secret=Depends(APIKeySecret)):\n",
      "    try:\n",
      "        base_url = f\"https://api.sikkasoft.com/v4/patient_balance/{patient_id}\"\n",
      "        headers = {\"Authorization\": f\"Bearer {apikey_secret.api_key}\"}\n",
      "        \n",
      "        response = requests.get(base_url, headers=headers)\n",
      "        \n",
      "        if response.status_code == 200:\n",
      "            return response.json()\n",
      "        else:\n",
      "            return {\"message\": \"Error: Unable to retrieve balance\", \"status_code\": response.status_code}\n",
      "    except Exception as e:\n",
      "        # Handle client-specific exceptions by logging the critical information and re-raising the exception.\n",
      "        return {\"message\": f\"Error in client-side logic: {str(e)}\", \"status_code\": 500}\n",
      "\n",
      "@app.get(\"/payment\")\n",
      "def make_payment(amount: float, card_number: int, payment_method: str = \"credit\"):\n",
      "    try:\n",
      "        # Using API Keys for Security\n",
      "        base_url = f\"https://api.sikkasoft.com/v4/balance/{card_number}\"\n",
      "        headers = {\"Authorization\": f\"Bearer {APIKeySecret(api_key='your_api_key', balance_id=card_number, payment_plans_api_key='payment_api').api_key}\"}\n",
      "        \n",
      "        response = requests.post(base_url, headers=headers, json={\"_amount\": amount})\n",
      "        \n",
      "        if response.status_code == 200:\n",
      "            return response.json()\n",
      "        else:\n",
      "            return {\"message\": \"Error: Unable to process payment\", \"status_code\": response.status_code}\n",
      "    except Exception as e:\n",
      "        # Handle client-specific exceptions by logging the critical information and re-raising the exception.\n",
      "        return {\"message\": f\"Error in client-side logic: {str(e)}\", \"status_code\": 500}\n",
      "\n",
      "```\n",
      "\n",
      "Additionally, consider refactoring your frontend code to use dependency injection for API keys and URLs:\n",
      "\n",
      "```javascript\n",
      "//PaymentSystem.js\n",
      "import axios from 'axios';\n",
      "\n",
      "class PaymentSystem {\n",
      "    private baseUrl: string;\n",
      "    private apikeysSecret;\n",
      "\n",
      "    constructor(baseUrl: string, apikeysSecret) {\n",
      "        this.baseUrl = baseUrl;\n",
      "        this.apikeysSecret = apikeysSecret;\n",
      "    }\n",
      "\n",
      "    async makePayment(amount: number, cardNumber: number, paymentMethod: \"credit\" | \"debit\"): Promise<any> {\n",
      "        const requestUrl = `${this.baseUrl}/payment/${paymentMethod}`;\n",
      "        \n",
      "        // Using API Keys\n",
      "        try {\n",
      "            const { data } = await axios.post(requestUrl, {\n",
      "                amount,\n",
      "                cardNumber\n",
      "            }, {\n",
      "                \n",
      "            });\n",
      "            return data;\n",
      "        }\n",
      "        catch (error) {\n",
      "            throw new Error(`Error from Payment Service: ${error.toString()}`);\n",
      "        }\n",
      "    }\n",
      "\n",
      "   async getBalance() : Promise<number>{\n",
      "       const requestUrl = `${this.baseUrl}/balance`;\n",
      "\n",
      "       try{\n",
      "        // Using API Keys\n",
      "          const {data }=await axios.get(requestUrl, this.apikeysSecret);\n",
      "            return data;\n",
      "       }\n",
      "       catch(error) {\n",
      "           throw new Error(`Error from Balance Service: ${error.toString()}`);\n",
      "\n",
      "       }\n",
      "\n",
      "   }\n",
      "}\n",
      "\n",
      "class APIKeySecret {\n",
      "    constructor(public api_key : string,\n",
      "                 public balance_id : string,\n",
      "                public payment_plans_api_key :string){\n",
      "                    this.api_key =api_key;\n",
      "                              this.balance_id=balance_id;this.payment_plana_api  ;\n",
      "                        }\n",
      "\n",
      "}\n",
      "```\n",
      "\n",
      "When running the system, make sure to update dependencies and follow secure methods of storing secrets like API keys.\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870d35d-a3c9-4cc9-9576-bfc8990583e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
